{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "825192e3",
   "metadata": {},
   "source": [
    "### Figure 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39be5af4",
   "metadata": {},
   "source": [
    "Install and import all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bdd3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import invian\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from osfclient import OSF\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.signal import find_peaks, periodogram, spectrogram, filtfilt, butter, find_peaks_cwt, correlate, welch, peak_prominences, resample\n",
    "from scipy.stats import ttest_rel, ttest_ind\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.size': 32, \n",
    "    'figure.autolayout': True, \n",
    "    'lines.linewidth': 2, \n",
    "    'axes.spines.top': False, \n",
    "    'axes.spines.right': False\n",
    "    })\n",
    "\n",
    "events_fixed = False\n",
    "\n",
    "print(\"The setup was successfully completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6144d0",
   "metadata": {},
   "source": [
    "Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9356b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pulse_split(event_ts, max_gap=0.3):\n",
    "    counter = 1\n",
    "    peak_dict = {}\n",
    "    time_diff = np.diff(event_ts)\n",
    "    i=0\n",
    "    while True:\n",
    "        \n",
    "        c_diff = time_diff[i]\n",
    "        if c_diff > max_gap:  \n",
    "            if counter not in peak_dict.keys():\n",
    "                peak_dict[counter] = []\n",
    "            \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            peak_dict[counter].append(event_ts[i])\n",
    "            \n",
    "            if i < (len(time_diff)-1):\n",
    "                counter = 1\n",
    "                i += 1\n",
    "                \n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        else:\n",
    "            while c_diff < max_gap:\n",
    "                counter += 1\n",
    "                if i < (len(time_diff)-1):\n",
    "                    i += 1\n",
    "                    c_diff = time_diff[i]\n",
    "                    \n",
    "                else:\n",
    "                    \n",
    "                    break\n",
    "                \n",
    "        if not i < (len(time_diff)-1):   \n",
    "            break\n",
    "\n",
    "    return peak_dict\n",
    "\n",
    "#Temp functions\n",
    "def butter_filter(signal, filt_type, freqs, sr, order=3):\n",
    "    b,a = butter(order, freqs, btype=filt_type, fs=sr)\n",
    "    y=filtfilt(b, a, signal, padtype=\"even\")\n",
    "    \n",
    "    return y\n",
    "\n",
    "#Peri-event histogram for continuous values.\n",
    "def contvar_peh(var_ts, var_vals, ref_ts, min_max, bin_width = False):\n",
    "    r\"\"\"\n",
    "    Function to perform a peri-event histogram of spiking activity.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    var_ts : array-like\n",
    "        Photometry signal timestamps\n",
    "    var_vals : array-like\n",
    "        Photometry signal values\n",
    "    ref_ts : array-like\n",
    "        Reference events that spiking will be aligned to\n",
    "    min_max : tuple\n",
    "        Time window in seconds around ref_ts to be analyzed in seconds. E.g. (-4,8)\n",
    "    bin_width : float\n",
    "        Bin width of histogram in seconds\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    all_trials : 2d-array\n",
    "        Continuous variable values around each timestamp in ref_ts in bin_width wide bins\n",
    "    \"\"\"\n",
    "    if not isinstance(var_ts,np.ndarray):\n",
    "        try:\n",
    "            var_ts = np.array(var_ts)          \n",
    "        except:\n",
    "            raise TypeError(f\"Expected spike_ts to be of type: array-like but got {type(var_ts)} instead\")\n",
    "        \n",
    "    if not isinstance(var_vals,np.ndarray):\n",
    "        try:\n",
    "            var_vals = np.array(var_vals)          \n",
    "        except:\n",
    "            raise TypeError(f\"Expected var_vals to be of type: array-like but got {type(var_vals)} instead\")\n",
    "    \n",
    "    if not isinstance(ref_ts,np.ndarray):\n",
    "        try:\n",
    "            ref_ts = np.array(ref_ts)     \n",
    "        except:\n",
    "            raise TypeError(f\"Expected spike_ts to be of type: array-like but got {type(ref_ts)} instead\")\n",
    "    \n",
    "    if bin_width:\n",
    "        ds_ts = np.linspace(var_ts.min(), var_ts.max(), int((var_ts.max()-var_ts.min())/bin_width))\n",
    "        ds_vals = resample(var_vals, ds_ts.size)\n",
    "            \n",
    "        #ds_vals = np.interp(ds_ts, var_ts, var_vals)\n",
    "        rate = bin_width\n",
    "    \n",
    "    else:\n",
    "        rate = np.diff(var_ts).mean()\n",
    "        ds_ts, ds_vals = (np.array(var_ts), np.array(var_vals))       \n",
    "        \n",
    "    left_idx = int(min_max[0]/rate)\n",
    "    right_idx = int(min_max[1]/rate)\n",
    "\n",
    "    event_ts = ref_ts[np.logical_and((ref_ts + min_max[0]) > ds_ts[0], (ref_ts + min_max[1]) < ds_ts[-1])]\n",
    "    if len(event_ts) < len(ref_ts):\n",
    "        event_diff = len(ref_ts) - len(event_ts)\n",
    "        warnings.warn(f\"The trial time range of {event_diff} events is outside the timestamps range. Events were ommitted.\")\n",
    "        \n",
    "    \n",
    "    all_idx = np.searchsorted(ds_ts,event_ts, \"right\")   \n",
    "    all_trials = np.vstack([ds_vals[idx+left_idx:idx+right_idx] for idx in all_idx])\n",
    "    \n",
    "    return all_trials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b75f503",
   "metadata": {},
   "source": [
    "Fetching the data from OSF and extracting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "output_dir = \"osf_downloads\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Connect to OSF\n",
    "osf = OSF()\n",
    "project = osf.project('stk2r')\n",
    "storage = project.storage('osfstorage')\n",
    "\n",
    "# Set up folder name with data\n",
    "target_filename = 'Behavioral_calcium.zip'\n",
    "\n",
    "# Download zip file with data\n",
    "for file in storage.files:\n",
    "    if file.name == target_filename:\n",
    "        output_path = os.path.join(output_dir, file.name)\n",
    "        with open(output_path, 'wb') as f:\n",
    "            file.write_to(f)\n",
    "        print(f\"Downloaded: {file.name} to {output_path}\")\n",
    "        break\n",
    "else:\n",
    "    print(f\"File '{target_filename}' not found in OSF storage.\")\n",
    "\n",
    "#Set up \n",
    "zip_path = 'osf_downloads/behavioral_calcium.zip'\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(output_dir)\n",
    "\n",
    "print(f\"Extracted all files to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9082d0",
   "metadata": {},
   "source": [
    "Formatting the data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ccd4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileloc = os.path.join(os.getcwd(), \"osf_downloads\", \"Behavioral_calcium\")\n",
    "\n",
    "raw_data = {\n",
    "    \"D1-Cre\": {\n",
    "        \"Saline\": {\n",
    "            \"F488\": pd.read_csv(fileloc + r\"\\saline_D1_F488_bandit_031825.csv\"),\n",
    "            \"M690\": pd.read_csv(fileloc + r\"\\saline_D1_M690_bandit_040325.csv\"),\n",
    "            \"M700\": pd.read_csv(fileloc + r\"\\saline_D1_M700_bandit_040325.csv\"),\n",
    "            \"M780\": pd.read_csv(fileloc + r\"\\saline_D1_M780_bandit_051325.csv\"),\n",
    "            \"F797\": pd.read_csv(fileloc + r\"\\saline_D1_F797_bandit_051325.csv\"),\n",
    "            },\n",
    "        \"MK801\": {\n",
    "            \"F488\": pd.read_csv(fileloc + r\"\\mk801_D1_F488_bandit_040425.csv\"),\n",
    "            \"M690\": pd.read_csv(fileloc + r\"\\mk801_D1_M690_bandit_042925.csv\"),\n",
    "            \"M700\": pd.read_csv(fileloc + r\"\\mk801_D1_M700_bandit_042525.csv\"),\n",
    "            \"M780\": pd.read_csv(fileloc + r\"\\mk801_D1_M780_bandit_060925.csv\"),\n",
    "            \"F797\": pd.read_csv(fileloc + r\"\\mk801_D1_F797_bandit_060925.csv\")\n",
    "            }\n",
    "        },\n",
    "    \"A2a-Cre\": {\n",
    "        \"Saline\": {\n",
    "            \"M521\": pd.read_csv(fileloc + r\"\\saline_A2a_M521_bandit_011025.csv\"),\n",
    "            \"C139M1\": pd.read_csv(fileloc + r\"\\saline_A2a_C139M1_bandit_041425.csv\"),\n",
    "            \"C139M2\": pd.read_csv(fileloc + r\"\\saline_A2a_C139M2_bandit_041425.csv\"),\n",
    "            \"C139M4\": pd.read_csv(fileloc + r\"\\saline_A2a_C139M4_bandit_040725.csv\")\n",
    "            },\n",
    "        \"MK801\": {\n",
    "            \"M521\": pd.read_csv(fileloc + r\"\\mk801_A2a_M521_bandit_030625.csv\"),\n",
    "            \"C139M1\": pd.read_csv(fileloc + r\"\\mk801_A2a_C139M1_bandit_050225.csv\"),\n",
    "            \"C139M4\": pd.read_csv(fileloc + r\"\\mk801_A2a_C139M4_bandit_042425.csv\"),\n",
    "            \"C139M2\": pd.read_csv(fileloc + r\"\\mk801_A2a_C139M2_bandit_042525.csv\")\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "events = {\n",
    "    \"D1-Cre\": {\n",
    "        \"Saline\": {\n",
    "            \"F488\": pd.read_csv(fileloc + r\"\\events_saline_D1_F488_bandit_031825.csv\", index_col=0),\n",
    "            \"M690\": pd.read_csv(fileloc + r\"\\events_saline_D1_M690_bandit_040325.csv\", index_col=0),\n",
    "            \"M700\": pd.read_csv(fileloc + r\"\\events_saline_D1_M700_bandit_040325.csv\", index_col=0),\n",
    "            \"M780\": pd.read_csv(fileloc + r\"\\events_saline_D1_M780_bandit_051325.csv\", index_col=0),\n",
    "            \"F797\": pd.read_csv(fileloc + r\"\\events_saline_D1_F797_bandit_051325.csv\", index_col=0)\n",
    "            },\n",
    "        \"MK801\": {\n",
    "            \"F488\": pd.read_csv(fileloc + r\"\\events_mk801_D1_F488_bandit_040425.csv\", index_col=0),\n",
    "            \"M690\": pd.read_csv(fileloc + r\"\\events_mk801_D1_M690_bandit_042925.csv\", index_col=0),\n",
    "            \"M700\": pd.read_csv(fileloc + r\"\\events_mk801_D1_M700_bandit_042525.csv\", index_col=0),\n",
    "            \"M780\": pd.read_csv(fileloc + r\"\\events_mk801_D1_M780_bandit_060925.csv\", index_col=0),\n",
    "            \"F797\": pd.read_csv(fileloc + r\"\\events_mk801_D1_F797_bandit_060925.csv\", index_col=0)\n",
    "            }\n",
    "        },\n",
    "    \"A2a-Cre\": {\n",
    "        \"Saline\": {\n",
    "            \"M521\": pd.read_csv(fileloc + r\"\\events_saline_A2a_M521_bandit_011025.csv\", index_col=0),\n",
    "            \"C139M1\": pd.read_csv(fileloc + r\"\\events_saline_A2a_C139M1_bandit_041425.csv\", index_col=0),\n",
    "            \"C139M2\": pd.read_csv(fileloc + r\"\\events_saline_A2a_C139M2_bandit_041425.csv\", index_col=0),\n",
    "            \"C139M4\": pd.read_csv(fileloc + r\"\\events_saline_A2a_C139M4_bandit_040725.csv\", index_col=0)\n",
    "            },\n",
    "        \"MK801\": {\n",
    "            \"M521\": pd.read_csv(fileloc + r\"\\events_mk801_A2a_M521_bandit_030625.csv\", index_col=0),\n",
    "            \"C139M4\": pd.read_csv(fileloc + r\"\\events_mk801_A2a_C139M4_bandit_042425.csv\", index_col=0),\n",
    "            \"C139M1\": pd.read_csv(fileloc + r\"\\events_mk801_A2a_C139M1_bandit_050225.csv\", index_col=0),\n",
    "            \"C139M2\": pd.read_csv(fileloc + r\"\\events_mk801_A2a_C139M2_bandit_042525.csv\", index_col=0)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "metadata = pd.read_csv(fileloc + r\"\\all_metadata_081425.csv\")\n",
    "\n",
    "print(\"All files were successfully formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4b36b2",
   "metadata": {},
   "source": [
    "Visualize Raw data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee7b38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There are:\n",
    "Two strains: \"D1-Cre\" and \"A2a-Cre\"\n",
    "Two treatments: \"Saline\", \"MK801\"\n",
    "Nine mice: \"F488\", \"M690\", \"M700\", \"M780\", \"F797\", \"M521\", \"C139M1\", \"C139M2\", \"C139M4\".\n",
    "\n",
    "A baseline of at least 15 mins. was first recorded for each mouse, then the mouse was injected. For most recordings, the mice were then placed back in their\n",
    "home-cages for at least 30 mins, and then they were plugged back in to the photometry system and recording was continued.\n",
    "\"\"\"\n",
    "strain = \"D1-Cre\"\n",
    "treatment = \"Saline\"\n",
    "mouse = \"M700\"\n",
    "\n",
    "c_t_data = raw_data[strain][treatment][mouse].copy(deep=True)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(c_t_data[\"Time\"], c_t_data[\"Fluorescence\"])\n",
    "ax.set_title(\"GCaMP Fluorescence\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(c_t_data[\"Time\"], c_t_data[\"Isosbestic\"])\n",
    "ax.set_title(\"Isosbestic Fluorescence\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c477e23",
   "metadata": {},
   "source": [
    "Pre-process behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45250a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The behavioral events were recorded using TTL pulses. Since it was all sent through one digital channel, a different number of pulses was sent for each event.\n",
    "The rekey variable describes how many pulses were sent for each event. Here split the events. In some recordings, pulses were incorrect, such that both the \n",
    "pellet drop and the pellet retrieval both sent 6 pulses. Given that pellet retrieval always follows pellet drop, we can fix it.\n",
    "\"\"\"\n",
    "rekey = {1: \"Left_poke\", 2: \"Right_poke\", 3: \"Rewarded\", 4: \"Unrewarded\", 5: \"Pellet_drop\", 6: \"Pellet_retrieval\"}\n",
    "p_events = {}\n",
    "for strain in events:\n",
    "    p_events[strain] = {}\n",
    "    for treatment in events[strain]:\n",
    "        p_events[strain][treatment] = {}\n",
    "        for mouse in events[strain][treatment]:\n",
    "            c_events = events[strain][treatment][mouse].to_numpy().squeeze()\n",
    "            c_split = pulse_split(c_events)\n",
    "            c_n_split = dict((rekey[key], value) for key,value in c_split.items())\n",
    "            p_events[strain][treatment][mouse] = c_n_split\n",
    "            \n",
    "        for mouse in events[strain][treatment]:\n",
    "            c_left_pokes = p_events[strain][treatment][mouse][\"Left_poke\"]\n",
    "            c_right_pokes = p_events[strain][treatment][mouse][\"Right_poke\"]\n",
    "            p_events[strain][treatment][mouse][\"Pokes\"] = c_left_pokes + c_right_pokes\n",
    "\n",
    "#Fixing recordings where both pellet drop and retrieval had 6 pulses\n",
    "p_events[\"D1-Cre\"][\"Saline\"][\"M690\"][\"Pellet_drop\"] = p_events[\"D1-Cre\"][\"Saline\"][\"M690\"][\"Pellet_retrieval\"][::2]\n",
    "p_events[\"D1-Cre\"][\"Saline\"][\"M690\"][\"Pellet_retrieval\"] = p_events[\"D1-Cre\"][\"Saline\"][\"M690\"][\"Pellet_retrieval\"][1::2]\n",
    "\n",
    "p_events[\"D1-Cre\"][\"Saline\"][\"M700\"][\"Pellet_drop\"] = p_events[\"D1-Cre\"][\"Saline\"][\"M700\"][\"Pellet_retrieval\"][::2]\n",
    "p_events[\"D1-Cre\"][\"Saline\"][\"M700\"][\"Pellet_retrieval\"] = p_events[\"D1-Cre\"][\"Saline\"][\"M700\"][\"Pellet_retrieval\"][1::2]\n",
    "\n",
    "p_events[\"A2a-Cre\"][\"Saline\"][\"C139M1\"][\"Pellet_drop\"] = p_events[\"A2a-Cre\"][\"Saline\"][\"C139M1\"][\"Pellet_retrieval\"][::2]\n",
    "p_events[\"A2a-Cre\"][\"Saline\"][\"C139M1\"][\"Pellet_retrieval\"] = p_events[\"A2a-Cre\"][\"Saline\"][\"C139M1\"][\"Pellet_retrieval\"][1::2]\n",
    "\n",
    "p_events[\"A2a-Cre\"][\"Saline\"][\"C139M2\"][\"Pellet_drop\"] = p_events[\"A2a-Cre\"][\"Saline\"][\"C139M2\"][\"Pellet_retrieval\"][::2]\n",
    "p_events[\"A2a-Cre\"][\"Saline\"][\"C139M2\"][\"Pellet_retrieval\"] = p_events[\"A2a-Cre\"][\"Saline\"][\"C139M2\"][\"Pellet_retrieval\"][1::2]\n",
    "\n",
    "p_events[\"A2a-Cre\"][\"Saline\"][\"C139M4\"][\"Pellet_drop\"] = p_events[\"A2a-Cre\"][\"Saline\"][\"C139M4\"][\"Pellet_retrieval\"][::2]\n",
    "p_events[\"A2a-Cre\"][\"Saline\"][\"C139M4\"][\"Pellet_retrieval\"] = p_events[\"A2a-Cre\"][\"Saline\"][\"C139M4\"][\"Pellet_retrieval\"][1::2]\n",
    "\n",
    "p_events[\"D1-Cre\"][\"MK801\"][\"M700\"][\"Pellet_drop\"] = p_events[\"D1-Cre\"][\"MK801\"][\"M700\"][\"Pellet_retrieval\"][::2]\n",
    "p_events[\"D1-Cre\"][\"MK801\"][\"M700\"][\"Pellet_retrieval\"] = p_events[\"D1-Cre\"][\"MK801\"][\"M700\"][\"Pellet_retrieval\"][1::2]\n",
    "\n",
    "p_events[\"A2a-Cre\"][\"MK801\"][\"C139M1\"][\"Pellet_drop\"] = p_events[\"A2a-Cre\"][\"MK801\"][\"C139M1\"][\"Pellet_retrieval\"][::2]\n",
    "p_events[\"A2a-Cre\"][\"MK801\"][\"C139M1\"][\"Pellet_retrieval\"] = p_events[\"A2a-Cre\"][\"MK801\"][\"C139M1\"][\"Pellet_retrieval\"][1::2]\n",
    "    \n",
    "print(\"Behavioral events successfully pre-processed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c381d0bc",
   "metadata": {},
   "source": [
    "Pre-process photometry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1464cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "The photometry data is processed in the following manner.\n",
    "A linear regression is used to fit the isosbestic data to the gcamp signal (noise_hat). The gcamp signal is processed as follows.\n",
    "    norm_gcamp = (raw_gcamp - noise_hat) / noise_hat\n",
    "This is analogous to a df/f given that the noise_hat represents the floor of the gcamp signal (f0). Importantly, the regression is fit on the\n",
    "baseline data, and this fitted regression is used for the calculation of the df/f of both the baseline and the post-MK801 data.\n",
    "This signal is then filtered using a bandpass digital filter that allows frequencies >0.005, <6 HZ.\n",
    "\"\"\"\n",
    "\n",
    "bp_filter = True\n",
    "\n",
    "p_base_gcamp = {}\n",
    "p_post_gcamp = {}\n",
    "for strain in raw_data:\n",
    "    p_base_gcamp[strain] = {}\n",
    "    p_post_gcamp[strain] = {}\n",
    "    for treatment in raw_data[strain]:\n",
    "        p_base_gcamp[strain][treatment] = {}\n",
    "        p_post_gcamp[strain][treatment] = {}\n",
    "        for mouse in raw_data[strain][treatment]:\n",
    "            #Here we get the corresponding raw data and metadata for each mouse\n",
    "            c_meta = metadata[np.logical_and(metadata[\"Mouse\"] == mouse, metadata[\"Treatment\"] == treatment)]\n",
    "            c_data = raw_data[strain][treatment][mouse]\n",
    "            \n",
    "            #Here we obtain the baseline \n",
    "            if not np.isnan(c_meta[\"Baseline_start\"]).values:\n",
    "                c_base_start_idx = np.searchsorted(c_data[\"Time\"], c_meta[\"Baseline_start\"].values)[0]\n",
    "                c_base_end_idx = np.searchsorted(c_data[\"Time\"], c_meta[\"Baseline_end\"].values)[0]\n",
    "            \n",
    "                c_baseline = c_data.iloc[c_base_start_idx:c_base_end_idx,:]\n",
    "                c_base_ts = c_baseline[\"Time\"].to_numpy()\n",
    "                c_base_gcamp = c_baseline[\"Fluorescence\"].to_numpy()\n",
    "                c_base_isos = c_baseline[\"Isosbestic\"].to_numpy()\n",
    "                c_sr = 1 / np.diff(c_base_ts).mean()\n",
    "                \n",
    "                #Here we fit the linear regression\n",
    "                c_regr = LinearRegression()\n",
    "                c_regr.fit(c_base_isos.reshape(-1,1), c_base_gcamp.reshape(-1,1))\n",
    "                c_base_hat = c_regr.predict(c_base_isos.reshape(-1,1))[:,0]\n",
    "                \n",
    "                c_base_gcamp_norm = (c_base_gcamp - c_base_hat) / c_base_hat[0]\n",
    "                \n",
    "                #Here we apply the bandpass filter\n",
    "                if bp_filter:\n",
    "                    c_f_gcamp = butter_filter(c_base_gcamp_norm, \"bandpass\", (0.005, 6), c_sr)\n",
    "\n",
    "                else:\n",
    "                    c_f_gcamp = c_base_gcamp_norm    \n",
    "                    \n",
    "                p_base_gcamp[strain][treatment][mouse] = (c_base_ts, c_f_gcamp)\n",
    "                \n",
    "\n",
    "            c_post_start_idx = np.searchsorted(c_data[\"Time\"], c_meta[\"Post_start\"])[0]\n",
    "            \n",
    "            if not np.isnan(c_meta[\"Post_end\"]).values:\n",
    "                c_post_end_idx = np.searchsorted(c_data[\"Time\"], c_meta[\"Post_end\"])[0]\n",
    "                c_post = c_data.iloc[c_post_start_idx: c_post_end_idx]\n",
    "                \n",
    "            else:\n",
    "                c_post = c_data.iloc[c_post_start_idx:]                    \n",
    "                \n",
    "            c_post_ts = c_post[\"Time\"].to_numpy()\n",
    "            c_post_gcamp = c_post[\"Fluorescence\"].to_numpy()\n",
    "            c_post_isos = c_post[\"Isosbestic\"].to_numpy()\n",
    "            c_sr = 1 / np.diff(c_post_ts).mean()\n",
    "            \n",
    "            c_post_hat = c_regr.predict(c_post_isos.reshape(-1,1))[:,0]\n",
    "            c_post_gcamp_norm = (c_post_gcamp - c_post_hat)/c_post_hat\n",
    "            \n",
    "            if bp_filter:\n",
    "                c_f_gcamp = butter_filter(c_post_gcamp_norm, \"high\", 0.001, c_sr)\n",
    "            else:\n",
    "                c_f_gcamp = c_post_gcamp_norm\n",
    "                \n",
    "            p_post_gcamp[strain][treatment][mouse] = (c_post_ts, c_f_gcamp)\n",
    "\n",
    "print(\"All photometry recordings where succesffully processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c505eb6d",
   "metadata": {},
   "source": [
    "Visualize the baseline and post-MK801 processed photometry signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e185cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There are:\n",
    "Two strains: \"D1-Cre\" and \"A2a-Cre\"\n",
    "Two treatments: \"Saline\", \"MK801\"\n",
    "Nine mice: \"F488\", \"M690\", \"M700\", \"M780\", \"F797\", \"M521\", \"C139M1\", \"C139M2\", \"C139M4\".\n",
    "\"\"\"\n",
    "\n",
    "strain = \"A2a-Cre\"\n",
    "treatment = \"Saline\"\n",
    "mouse = \"M521\"\n",
    "\n",
    "if mouse in p_base_gcamp[strain][treatment]:\n",
    "    t_baseline = p_base_gcamp[strain][treatment][mouse]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(t_baseline[0], t_baseline[1])\n",
    "    \n",
    "else:\n",
    "    print(f\"{strain} {treatment} {mouse} has no baseline\")\n",
    "\n",
    "if mouse in p_post_gcamp[strain][treatment]:\n",
    "    t_post = p_post_gcamp[strain][treatment][mouse]\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(t_post[0], t_post[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1153a080",
   "metadata": {},
   "source": [
    "Calculating peri-event histogram for all behavioral events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36db0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PEH window (in seconds) of each behavioral event \n",
    "event_windows = {\n",
    "    \"Left_poke\": (-2,2),\n",
    "    \"Right_poke\": (-2,2),\n",
    "    \"Pokes\": (-2,2),\n",
    "    \"Rewarded\": (-4,4),\n",
    "    \"Unrewarded\": (-4,4),\n",
    "    \"Pellet_drop\": (-10,15),\n",
    "    \"Pellet_retrieval\": (-20,20)\n",
    "    }\n",
    "bin_width = 0.1\n",
    "norm_bins = 50\n",
    "event_pehs = {}\n",
    "for strain in p_post_gcamp:\n",
    "    event_pehs[strain] = {}\n",
    "    \n",
    "    for treatment in p_post_gcamp[strain]:\n",
    "        event_pehs[strain][treatment] = {}\n",
    "        \n",
    "        for mouse in p_post_gcamp[strain][treatment]:\n",
    "            #print(f\"Calculating PEHs of {strain}, {treatment}, {mouse}\")\n",
    "            event_pehs[strain][treatment][mouse] = {}\n",
    "            \n",
    "            c_ts = p_post_gcamp[strain][treatment][mouse][0]\n",
    "            c_gcamp = p_post_gcamp[strain][treatment][mouse][1]\n",
    "            c_all_events = p_events[strain][treatment][mouse]\n",
    "            \n",
    "            for event_name in event_windows:\n",
    "                c_event = c_all_events[event_name]\n",
    "                c_window = event_windows[event_name]\n",
    "                \n",
    "                #c_peh = invian.contvar_peh(c_ts, c_gcamp, c_event, min_max=c_window, bin_width=bin_width)\n",
    "                c_peh = contvar_peh(c_ts, c_gcamp, c_event, min_max=c_window, bin_width=bin_width)\n",
    "                c_norm_peh = c_peh - (c_peh[:,:norm_bins].mean(axis=1)[:,np.newaxis])\n",
    "                \n",
    "                event_pehs[strain][treatment][mouse][event_name] = c_norm_peh\n",
    "\n",
    "print(\"All PEHs have been successfully calculated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c933e79",
   "metadata": {},
   "source": [
    "Visualizing PEH for each mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8888b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There are:\n",
    "5 Behavioral event: \"Left_poke\", \"Right_poke\", \"Rewarded\", \"Unrewarded\", \"Pellet_drop\", \"Pellet_retrieval\"\n",
    "Two strains: \"D1-Cre\" and \"A2a-Cre\"\n",
    "Two treatments: \"Saline\", \"MK801\"\n",
    "Nine mice: \"F488\", \"M690\", \"M700\", \"M780\", \"F797\", \"M521\", \"C139M1\", \"C139M2\", \"C139M4\". See loading data cell to \n",
    "check which mice belong to which strain.\n",
    "\"\"\"\n",
    "\n",
    "#From the options, you can select the specific mouse\n",
    "event_name = \"Pellet_retrieval\"\n",
    "strain = \"D1-Cre\"\n",
    "treatment = \"MK801\"\n",
    "mouse = \"F797\"\n",
    "\n",
    "c_window = event_windows[event_name]\n",
    "if mouse == \"all\":\n",
    "    c_data = event_pehs[strain][treatment]\n",
    "    \n",
    "    if (event_name == \"Pellet_drop\") or (event_name == \"Pellet_retrieval\"):\n",
    "        y_lim = (-2,1)\n",
    "    else:\n",
    "        y_lim = (-0.5,1)\n",
    "    \n",
    "    for c_mouse in c_data:\n",
    "        c_peh = event_pehs[strain][treatment][c_mouse][event_name]\n",
    "        \n",
    "        fig, ax = plt.subplots(2,1, figsize=(8,8))\n",
    "        sns.heatmap(c_peh, ax=ax[0], cbar=False, xticklabels=False)\n",
    "        ax[1].plot(np.linspace(c_window[0], c_window[1],c_peh.shape[1]), c_peh[:].mean(axis=0))\n",
    "        #ax[1].set_xlim(c_window[0], c_window[1])\n",
    "        ax[0].set_title(f\"{event_name}, {strain}, {treatment}, {c_mouse}\")\n",
    "        #ax[1].set_ylim(y_lim[0], y_lim[1])\n",
    "        ax[1].set_xlabel(f\"Time from {event_name}\")\n",
    "        ax[1].set_ylabel(\"Z-Score\")\n",
    "        sns.despine(ax=ax[1])\n",
    "        \n",
    "else:\n",
    "    c_peh = event_pehs[strain][treatment][mouse][event_name]\n",
    "    \n",
    "    if (event_name == \"Pellet_drop\") or (event_name == \"Pellet_retrieval\"):\n",
    "        y_lim = (-2,1)\n",
    "    else:\n",
    "        y_lim = (-0.5,1)\n",
    "    \n",
    "    fig, ax = plt.subplots(2,1, figsize=(8,8))\n",
    "    sns.heatmap(c_peh, ax=ax[0], cbar=False, xticklabels=False)\n",
    "    ax[1].plot(np.linspace(c_window[0], c_window[1],c_peh.shape[1]), c_peh.mean(axis=0))\n",
    "    ax[1].set_xlim(c_window[0], c_window[1])\n",
    "    ax[0].set_title(f\"{event_name}, {strain}, {treatment}, {mouse}\")\n",
    "    ax[1].set_xlabel(f\"Time from {event_name}\")\n",
    "    ax[1].set_ylabel(r\"$\\Delta F/F_0$\")\n",
    "    sns.despine(ax=ax[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11979169",
   "metadata": {},
   "source": [
    "Calculate and plot average pellet retrieval response after saline and MK801 injections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a598f6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We find the mean response for each mouse, and we pool and format the data for plotting.\n",
    "\"\"\"\n",
    "\n",
    "pr_bins = np.arange(event_windows[\"Pellet_retrieval\"][0],event_windows[\"Pellet_retrieval\"][1], 0.1)\n",
    "all_pr_avgs = []\n",
    "for strain in event_pehs:\n",
    "    for treatment in event_pehs[strain]:\n",
    "        for mouse in event_pehs[strain][treatment]:\n",
    "            c_pr_peh = event_pehs[strain][treatment][mouse][\"Pellet_retrieval\"]\n",
    "            c_pr_peh_avg = c_pr_peh.mean(axis=0)\n",
    "            \n",
    "            pr_peh_avg_df = pd.DataFrame({\"Value\": c_pr_peh_avg, \"Time\": pr_bins})\n",
    "            pr_peh_avg_df = pr_peh_avg_df.assign(Strain=strain, Treatment=treatment, Mouse=mouse)\n",
    "            all_pr_avgs.append(pr_peh_avg_df)\n",
    "            \n",
    "concat_pr_avgs = pd.concat(all_pr_avgs)\n",
    "sal_pr_avgs = concat_pr_avgs[concat_pr_avgs[\"Treatment\"] == \"Saline\"]\n",
    "mk801_pr_avgs = concat_pr_avgs[concat_pr_avgs[\"Treatment\"] == \"MK801\"]\n",
    "\n",
    "#Plotting of the peri-event histogram\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.lineplot(x=\"Time\", y=\"Value\", hue=\"Treatment\", data=concat_pr_avgs, errorbar=None, palette=[\"darkcyan\", \"olive\"], linewidth=3, legend=False)\n",
    "sns.lineplot(x=\"Time\", y=\"Value\", hue=\"Mouse\", data=sal_pr_avgs, errorbar=None, palette=[\"darkcyan\"], alpha=0.2, linewidth=3, legend=False)\n",
    "sns.lineplot(x=\"Time\", y=\"Value\", hue=\"Mouse\", data=mk801_pr_avgs, errorbar=None, palette=[\"olive\"], alpha=0.2, linewidth=3, legend=False)\n",
    "sns.despine()\n",
    "ax.set_ylabel(r\"$\\Delta F/F_0$\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.axvline(0, c=\"red\", linestyle=\"--\", linewidth=3)\n",
    "ax.spines[\"left\"].set_linewidth(2)\n",
    "ax.spines[\"bottom\"].set_linewidth(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ce8995",
   "metadata": {},
   "source": [
    "Find the average pre-retrieval maximum response and post-retrieval minimum response and format for plotting and statistical testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca14a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We find the average maximum pre-retrieval and minimum post-retrieval responses\n",
    "max_responses = []\n",
    "for strain in event_pehs:\n",
    "    for treatment in event_pehs[strain]:\n",
    "        for mouse in event_pehs[strain][treatment]:\n",
    "            for event in event_pehs[strain][treatment][mouse]:\n",
    "                c_peh = event_pehs[strain][treatment][mouse][event]\n",
    "                \n",
    "                if event == \"Pellet_retrieval\":\n",
    "                    c_max_pre = c_peh[:,70:100].max(axis=1)\n",
    "                    c_max_pre_avg = c_max_pre.mean()\n",
    "                    \n",
    "                    c_inhibition = c_peh[:,100:].min(axis=1)\n",
    "                    c_inhibition_avg = c_inhibition.mean()\n",
    "                    \n",
    "                    c_max_resp = pd.DataFrame({\n",
    "                        \"Mouse\": mouse,\n",
    "                        \"Treatment\": treatment,\n",
    "                        \"Strain\": strain,\n",
    "                        \"Pre_max\": [c_max_pre_avg],\n",
    "                        \"Post_min\": [c_inhibition_avg]\n",
    "                        })\n",
    "                    \n",
    "                    max_responses.append(c_max_resp)\n",
    "                \n",
    "concat_responses = pd.concat(max_responses)\n",
    "\n",
    "#Plotting boxplot of maximum pre-retrieval response\n",
    "fig, ax = plt.subplots(figsize=(5.5,8))\n",
    "sns.boxplot(x=\"Treatment\", y=\"Pre_max\", data=concat_responses, palette=[\"darkcyan\", \"olive\"])\n",
    "sns.swarmplot(x=\"Treatment\", y=\"Pre_max\", data=concat_responses, palette=[\"silver\"], s=10, dodge=False)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(r\"Pre-retrieval Max. $\\Delta F/F_0$\")\n",
    "ax.set_xticklabels([\"Sal\", \"MK801\"])\n",
    "sns.despine()\n",
    "\n",
    "#Plotting boxplot of minimum post-retrieval response\n",
    "fig, ax = plt.subplots(figsize=(5.5,8))\n",
    "sns.boxplot(x=\"Treatment\", y=\"Post_min\", data=concat_responses, palette=[\"darkcyan\", \"olive\"])\n",
    "sns.swarmplot(x=\"Treatment\", y=\"Post_min\", data=concat_responses, palette=[\"silver\"], s=10, dodge=False)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_ylabel(r\"Post-retrieval Min. $\\Delta F/F_0$\")\n",
    "ax.set_xticklabels([\"Sal\", \"MK801\"])\n",
    "ax.set_yticks(np.arange(-0.03,0.01, 0.01))\n",
    "ax.set_ylim(-0.035,0.005)\n",
    "sns.despine()\n",
    "\n",
    "#Statistical testing\n",
    "pre_resp_ttest = ttest_rel(concat_responses[\"Pre_max\"][concat_responses[\"Treatment\"] == \"Saline\"], \n",
    "                           concat_responses[\"Pre_max\"][concat_responses[\"Treatment\"] == \"MK801\"])\n",
    "post_resp_ttest = ttest_rel(concat_responses[\"Post_min\"][concat_responses[\"Treatment\"] == \"Saline\"], \n",
    "                            concat_responses[\"Post_min\"][concat_responses[\"Treatment\"] == \"MK801\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "influxdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
